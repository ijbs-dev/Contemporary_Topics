{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_6AEZPepx4cm","executionInfo":{"status":"ok","timestamp":1725071979342,"user_tz":180,"elapsed":5066,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wgLbAuLjx4co","executionInfo":{"status":"ok","timestamp":1725071979344,"user_tz":180,"elapsed":14,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"outputs":[],"source":["d_model = 512\n","num_heads = 8\n","d_ff = 2048\n","batch_size = 32"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"m9wIleYvx4cp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071979345,"user_tz":180,"elapsed":13,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"1fd0ea8a-eaea-45b5-cc98-e4fdc86a0db8"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 32, 512])\n"]}],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0), :]\n","\n","# Exemplo\n","max_len = 100\n","pos_encoding = PositionalEncoding(d_model, max_len)\n","\n","# (sequence_length, batch_size, d_model)\n","input_tensor = torch.randn(50, batch_size, d_model)\n","output_tensor = pos_encoding(input_tensor)\n","\n","print(output_tensor.shape)  # Output shape: (sequence_length, batch_size, d_model)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"e6tURvSCx4cq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071979698,"user_tz":180,"elapsed":363,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"e6f76a9b-1358-4cfb-a9a4-b4f6d8fb5d2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        # Verifica se o número de dimensões do modelo é divisível pelo número de cabeças\n","        assert d_model % num_heads == 0\n","\n","        # Número de dimensões por cabeça\n","        self.d_k = d_model // num_heads\n","        self.num_heads = num_heads\n","\n","        # Inicializa as camadas lineares para QUERY(W_q), KEY(W_k) e VALUES(W_v)\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        # Calcula os scores fazendo o produto escalar entre Q e K e dividindo pela raiz quadrada de d_k\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","\n","        # Se a máscara for fornecida, aplica a máscara para os scores\n","        if mask is not None:\n","            scores = scores.masked_fill(mask == 0, float('-inf'))\n","\n","        # Calcula a softmax nos scores\n","        attention = torch.softmax(scores, dim=-1)\n","\n","        # Multiplica a matriz de atenção pelo valor V\n","        output = torch.matmul(attention, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        # Divide a última dimensão em (num_heads, d_k)\n","        N, seq_len, d_model = x.size()\n","        return x.view(N, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        # Inverte a operação de split_heads\n","        N, _, seq_len, _ = x.size()\n","        return x.transpose(1, 2).contiguous().view(N, seq_len, self.num_heads * self.d_k)\n","\n","    def forward(self, query, key, value, mask=None):\n","        N = query.shape[0]\n","        query_len, key_len, value_len = query.shape[1], key.shape[1], value.shape[1]\n","\n","        # Passa os valores de Q, K e V pela camada linear\n","        Q = self.split_heads(self.W_q(query))\n","        K = self.split_heads(self.W_k(key))\n","        V = self.split_heads(self.W_v(value))\n","\n","        # Calcula a atenção\n","        attention = self.scaled_dot_product_attention(Q, K, V, mask)\n","\n","        # Combina as cabeças e aplica a camada linear final\n","        output = self.combine_heads(attention)\n","        output = self.W_o(output)\n","        return output\n","\n","\n","multi_head_attn = MultiHeadAttention(d_model, num_heads)\n","\n","# (batch_size, sequence_length, d_model)\n","query = torch.randn(batch_size, 50, d_model)\n","key = torch.randn(batch_size, 50, d_model)\n","value = torch.randn(batch_size, 50, d_model)\n","\n","output = multi_head_attn(query, key, value)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"For68SDGx4cr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071980071,"user_tz":180,"elapsed":384,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"35c4dd69-9ebf-47d3-d0a3-8d04eb2931c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super().__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))\n","\n","\n","d_model = 512\n","d_ff = 2048\n","ffn = FeedForward(d_model, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = ffn(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VWRvB_eDx4cr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071980071,"user_tz":180,"elapsed":10,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"a6c00b3b-39ae-4375-df85-7459ed7a412c"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        attn_output = self.attention(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ffn_output = self.ffn(x)\n","        x = self.norm2(x + self.dropout(ffn_output))\n","        return x\n","\n","\n","encoder_layer = EncoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = encoder_layer(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"JdUbdg1bx4cs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071983362,"user_tz":180,"elapsed":3297,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"f8d5037a-7b19-4eb0-8a9a-0f69f60a1f43"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 512])\n"]}],"source":["class Encoder(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        return x\n","\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","encoder = Encoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = encoder(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ho-UdbHHx4cs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071983732,"user_tz":180,"elapsed":375,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"a5744d27-b91c-4d9e-ba56-13970b9dd359"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.self_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.cross_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Self-attention na sequência de destino\n","        self_attn_output = self.self_attention(x, x, x, trg_mask)\n","        x = self.norm1(x + self.dropout(self_attn_output))\n","\n","        # Cross-attention entre a saída do self-attention e a saída do encoder\n","        cross_attn_output = self.cross_attention(x, enc_out, enc_out, src_mask)\n","        x = self.norm2(x + self.dropout(cross_attn_output))\n","\n","        # Feed-forward\n","        ffn_output = self.ffn(x)\n","        x = self.norm3(x + self.dropout(ffn_output))\n","\n","        return x\n","\n","\n","decoder_layer = DecoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","enc_out = torch.randn(32, 50, d_model)\n","\n","output = decoder_layer(input_tensor, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ecW_lzp9x4cs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071987683,"user_tz":180,"elapsed":3957,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"03d23849-5df9-4f09-c05a-b15eddb6417b"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Decoder\n","class Decoder(nn.Module):\n","    def __init__(self, trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(trg_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do decoder\n","        for layer in self.layers:\n","            x = layer(x, enc_out, src_mask, trg_mask)\n","\n","        out = self.fc_out(x)\n","        return out\n","\n","\n","trg_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","decoder = Decoder(trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","trg_seq = torch.randint(0, trg_vocab_size, (32, 100))\n","enc_out = torch.randn(32, 100, d_model)\n","\n","output = decoder(trg_seq, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"jxzF_sryx4cu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071996173,"user_tz":180,"elapsed":8498,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"67559371-8f9b-49d2-a10a-73c20f680285"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Transformer Completo\n","class Transformer(nn.Module):\n","    def __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size, d_model, num_heads, num_encoder_layers, d_ff, max_len, dropout)\n","        self.decoder = Decoder(trg_vocab_size, d_model, num_heads, num_decoder_layers, d_ff, max_len, dropout)\n","\n","    def generate_mask(self, src, trg):\n","        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n","        trg_mask = (trg != 0).unsqueeze(1).unsqueeze(3)\n","        seq_length = trg.size(1)\n","        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n","        trg_mask = trg_mask & nopeak_mask\n","        return src_mask, trg_mask\n","\n","    def forward(self, src, trg, src_mask=None, trg_mask=None):\n","        src_mask, trg_mask = self.generate_mask(src, trg)\n","        enc_out = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n","        return out\n","\n","\n","src_vocab_size = 1000\n","trg_vocab_size = 1000\n","d_model = 512\n","num_heads = 8\n","num_encoder_layers = 6\n","num_decoder_layers = 6\n","d_ff = 2048\n","max_len = 100\n","\n","transformer = Transformer(src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","src_seq = torch.randint(0, src_vocab_size, (batch_size, 100))\n","trg_seq = torch.randint(0, trg_vocab_size, (batch_size, 100))\n","\n","output = transformer(src_seq, trg_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, target_sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"d-PtA_Cbx4cu","executionInfo":{"status":"ok","timestamp":1725071996174,"user_tz":180,"elapsed":27,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"outputs":[],"source":["# Gerando as máscaras de forma separada\n","\n","def create_padding_mask(seq):\n","    return (seq != 0).unsqueeze(1).unsqueeze(2).type(torch.uint8)  # Cria uma máscara para posições de preenchimento\n","\n","def create_look_ahead_mask(size):\n","    mask = (1 - torch.triu(torch.ones(size, size), diagonal=1)).type(torch.uint8)\n","    return mask  # Cria uma máscara triangular para impedir a atenção em tokens futuros"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"r0TSSTt5x4cv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071996175,"user_tz":180,"elapsed":26,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"7e2cceaa-e9f4-48da-ab4d-8efa8a9e1be6"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1, 1, 0, 1, 0]]]], dtype=torch.uint8)\n"]}],"source":["seq = torch.tensor([[1, 2, 0, 4, 0]])\n","padding_mask = create_padding_mask(seq)\n","print(padding_mask)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xLGDes5zx4cv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725071996175,"user_tz":180,"elapsed":24,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"6da623b7-f886-4405-972f-38d8b748b401"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 0, 0, 0, 0],\n","        [1, 1, 0, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]], dtype=torch.uint8)\n"]}],"source":["look_ahead_mask = create_look_ahead_mask(5)\n","print(look_ahead_mask)"]},{"cell_type":"markdown","metadata":{"id":"h32fDmjPx4cw"},"source":["## Exercícios"]},{"cell_type":"markdown","metadata":{"id":"iZXnMfrZx4cx"},"source":["### Exercício 1\n","Implemente um módulo que utilize apenas o módulo Encoder para a classificação de texto em `num_classes` classes. Para a obtenção do vetor de embedding de toda a sequência que será enviado para a cabeça de classificação, faça um pooling de média através da dimensão de sequência."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"oouNJMztx4cx","executionInfo":{"status":"ok","timestamp":1725071996176,"user_tz":180,"elapsed":20,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"outputs":[],"source":["class TextClassifier(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes, dropout=0.1):\n","        super(TextClassifier, self).__init__()\n","        # Usamos o Encoder do Transformer\n","        self.encoder = Encoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout)\n","        # Camada linear para classificação\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x, mask=None):\n","        # Passando pela camada de encoder\n","        enc_out = self.encoder(x, mask)\n","        # Aplicando o pooling de média ao longo da dimensão de sequência\n","        pooled_output = torch.mean(enc_out, dim=1)\n","        # Passando o resultado pela camada linear para classificação\n","        out = self.fc(pooled_output)\n","        return out\n"]},{"cell_type":"code","source":["# Parâmetros\n","src_vocab_size = 1000\n","d_model = 512\n","num_heads = 8\n","num_layers = 6\n","d_ff = 2048\n","max_len = 100\n","num_classes = 10  # Número de classes para a classificação\n"],"metadata":{"id":"Q0PoRlxAQajv","executionInfo":{"status":"ok","timestamp":1725071996176,"user_tz":180,"elapsed":19,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Inicializando o modelo de classificação de texto\n","model = TextClassifier(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes)\n"],"metadata":{"id":"24QblgPUQcYO","executionInfo":{"status":"ok","timestamp":1725071996176,"user_tz":180,"elapsed":18,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Simulando uma sequência de entrada\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))  # (batch_size, sequence_length)\n","\n","# Fazendo a predição\n","output = model(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, num_classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqKLSGTFQgBF","executionInfo":{"status":"ok","timestamp":1725071998841,"user_tz":180,"elapsed":2679,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"cedc1352-57fa-4ff9-9993-7d2585bcf10c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ayKqX7Cbx4cx"},"source":["### Exercício 2\n","Vamos implementar um modelo baseado em stack de decoders. Uma vez que não é necessário cross-attention, pois não há encoders, utilize o módulo `EncoderLayer`. O tamanho do vocabulário deverá ser de 50257, o tamanho dos embeddings de 768, 12 cabeças de atenção, 12 camadas, dimensão da camada feedforward de 3072 e tamanho máximo de sequência 1024. Em seguida, teste com valores aleatórios simulando uma sequência de tokens."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"57qRR1Obx4cy","executionInfo":{"status":"ok","timestamp":1725071998842,"user_tz":180,"elapsed":15,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"outputs":[],"source":["class DecoderStack(nn.Module):\n","    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super(DecoderStack, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do \"decoder\"\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        out = self.fc_out(x)\n","        return out\n","\n"]},{"cell_type":"code","source":["# Parâmetros\n","vocab_size = 50257\n","d_model = 768\n","num_heads = 12\n","num_layers = 12\n","d_ff = 3072\n","max_len = 1024\n"],"metadata":{"id":"MM92jFk-Qrxg","executionInfo":{"status":"ok","timestamp":1725071998843,"user_tz":180,"elapsed":15,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Inicializando o modelo baseado em stack de decoders\n","model = DecoderStack(vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# Simulando uma sequência de entrada\n","input_seq = torch.randint(0, vocab_size, (8, 512))  # (batch_size, sequence_length)\n","\n","# Fazendo a predição\n","output = model(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMYXL3DiQuf3","executionInfo":{"status":"ok","timestamp":1725072023641,"user_tz":180,"elapsed":24810,"user":{"displayName":"ISMAEL JEFTE BISPO DA SILVA","userId":"01737244550443932188"}},"outputId":"db628f91-3bfc-4753-f5dd-efd14648ddad"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 512, 50257])\n"]}]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[{"file_id":"https://github.com/silvaan/topicos_contemporaneos/blob/main/Part%202%20-%20LLMs/03%20-%20Transformers.ipynb","timestamp":1723586845659}]}},"nbformat":4,"nbformat_minor":0}